{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bbdff1",
   "metadata": {},
   "source": [
    "## Recomendation engine with LLm + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98730637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rokri\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import random\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051badac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_minute</th>\n",
       "      <th>date_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72000</td>\n",
       "      <td>2571</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72000</td>\n",
       "      <td>4993</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000</td>\n",
       "      <td>296</td>\n",
       "      <td>3.5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72000</td>\n",
       "      <td>5952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72000</td>\n",
       "      <td>480</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850668</th>\n",
       "      <td>71331</td>\n",
       "      <td>62796</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851719</th>\n",
       "      <td>71420</td>\n",
       "      <td>3585</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852677</th>\n",
       "      <td>71420</td>\n",
       "      <td>59065</td>\n",
       "      <td>1.5</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>2008</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853205</th>\n",
       "      <td>71483</td>\n",
       "      <td>4421</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2003</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854772</th>\n",
       "      <td>71509</td>\n",
       "      <td>8393</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10109 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userID  movieID  rating  date_day  date_month  date_year  date_hour  \\\n",
       "0        72000     2571     4.0        20           6       2019         19   \n",
       "1        72000     4993     4.0        20           6       2019         19   \n",
       "2        72000      296     3.5        20           6       2019         19   \n",
       "3        72000     5952     4.0        20           6       2019         19   \n",
       "4        72000      480     3.0        20           6       2019         19   \n",
       "...        ...      ...     ...       ...         ...        ...        ...   \n",
       "850668   71331    62796     3.0        19          11       2008         23   \n",
       "851719   71420     3585     4.0        22          11       2007         22   \n",
       "852677   71420    59065     1.5        30          10       2008         15   \n",
       "853205   71483     4421     2.5         2           9       2003         22   \n",
       "854772   71509     8393     3.0        17           5       2005         20   \n",
       "\n",
       "        date_minute  date_second  \n",
       "0                17           16  \n",
       "1                17           16  \n",
       "2                17           16  \n",
       "3                17           16  \n",
       "4                17           16  \n",
       "...             ...          ...  \n",
       "850668           10           40  \n",
       "851719           43            7  \n",
       "852677           41           38  \n",
       "853205           18           25  \n",
       "854772           34           15  \n",
       "\n",
       "[10109 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To je za osebno testiranje baze\n",
    "df = pd.read_csv(\"data/user_ratedmovies.dat\", sep=\"\\t\")\n",
    "\n",
    "df_unique_movieID = df.drop_duplicates(subset=[\"movieID\"])\n",
    "df_unique_movieID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e08b194",
   "metadata": {},
   "source": [
    "Dodajanje stolpcev date, ki ga sestavimo iz podatkov in ratings_count, kjer prešejemo število ocen za posamezen film (movieID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec4fdc",
   "metadata": {},
   "source": [
    "Tle sm meu težave, ker moram naprej sortirati po datumu in potem šele po ratingih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d427b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserItemData:\n",
    "    def __init__(self, path, start_date=None, end_date=None, min_ratings=None):\n",
    "        self.path = path\n",
    "        self.start_date = pd.to_datetime(start_date, dayfirst=True) if start_date else None\n",
    "        self.end_date = pd.to_datetime(end_date, dayfirst=True) if end_date else None\n",
    "        self.min_ratings = min_ratings\n",
    "        self.df = self.init_df()\n",
    "        self.users_reviews = dict()\n",
    "        self.movie_reviews = dict()\n",
    "        self.users_reviews_list = dict()\n",
    "\n",
    "    def init_df(self):\n",
    "        df = pd.read_csv(self.path, sep=\"\\t\", encoding=\"latin1\")\n",
    "        df[\"date\"] = pd.to_datetime( df[\"date_day\"].astype(str) + \".\" + df[\"date_month\"].astype(str) + \".\" + df[\"date_year\"].astype(str), format=\"%d.%m.%Y\", dayfirst=True)\n",
    "\n",
    "        if self.start_date is not None:\n",
    "            df = df[df[\"date\"] >= self.start_date]\n",
    "\n",
    "        if self.end_date is not None:\n",
    "            df = df[df[\"date\"] < self.end_date]\n",
    "\n",
    "        df[\"ratings_count\"] = df.groupby(\"movieID\")[\"rating\"].transform(\"count\")\n",
    "\n",
    "        if self.min_ratings is not None:\n",
    "            df = df[df[\"ratings_count\"] >= self.min_ratings]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def nratings(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def nusers(self):\n",
    "        return len(self.df[\"userID\"].unique())\n",
    "    \n",
    "    def nitems(self):\n",
    "        return len(self.df[\"movieID\"].unique())\n",
    "    \n",
    "    def get_movie_ids(self):\n",
    "        return self.df[\"movieID\"].unique()\n",
    "    \n",
    "    def get_user_ids(self):\n",
    "        return self.df[\"userID\"].unique()\n",
    "    \n",
    "    def sum_ratings_for_movie(self, movieid):\n",
    "        vs = sum(self.df[self.df[\"movieID\"] == movieid][\"rating\"])\n",
    "        return vs\n",
    "    \n",
    "    def nratings_for_movie(self, movieid):\n",
    "        n = self.df[self.df[\"movieID\"] == movieid].shape[0]\n",
    "        return n\n",
    "    \n",
    "    def average_rating(self):\n",
    "        return sum(self.df[\"rating\"]) / self.nratings()\n",
    "    \n",
    "    def movieid_user_has_rated(self, userid):\n",
    "        res = set(self.df[self.df[\"userID\"] == userid][\"movieID\"])\n",
    "        return res\n",
    "    \n",
    "    # za ViewsPredictor\n",
    "    def len_ratings_for_movieid(self, movieid):\n",
    "        res = len(self.df[self.df[\"movieID\"] == movieid])\n",
    "        return res\n",
    "    \n",
    "    # za STDPredictor\n",
    "    def ratings_for_movieid(self, movieid):\n",
    "        res = list(self.df[self.df[\"movieID\"] == movieid][\"rating\"])\n",
    "        return res\n",
    "    \n",
    "    def get_user_reviews(self, userID):\n",
    "        if not self.users_reviews:\n",
    "            self.init_user_reviews()\n",
    "\n",
    "        return self.users_reviews.get(userID, dict())\n",
    "    \n",
    "    # { userID : [(ocena1, film1), (ocena2, film2)...] }\n",
    "    def init_user_reviews(self):\n",
    "        for userID, user_df in self.df.groupby(\"userID\", sort=False):\n",
    "            ratingsForUser = user_df[\"rating\"].to_list()\n",
    "            movieIDsForUser = user_df[\"movieID\"].to_list()\n",
    "\n",
    "            pairs_list = zip(movieIDsForUser, ratingsForUser)\n",
    "\n",
    "            self.users_reviews[userID] = dict(pairs_list)\n",
    "\n",
    "    def get_user_reviews_as_list(self, userID):\n",
    "        if not self.users_reviews_list:\n",
    "            self.init_user_reviews_as_list()\n",
    "\n",
    "        return self.users_reviews_list.get(userID, [])\n",
    "\n",
    "    def init_user_reviews_as_list(self):\n",
    "        for userID, user_df in self.df.groupby(\"userID\", sort=False):\n",
    "            ratingsForUser = user_df[\"rating\"].to_list()\n",
    "            movieIDsForUser = user_df[\"movieID\"].to_list()\n",
    "\n",
    "            pairs_list = list(zip(movieIDsForUser, ratingsForUser))\n",
    "\n",
    "            self.users_reviews_list[userID] = list(pairs_list)\n",
    "\n",
    "    def init_movie_reviews(self):\n",
    "        for movieID, movie_df in self.df.groupby(\"movieID\", sort=False):\n",
    "            ratingsForMovie = movie_df[\"rating\"].to_list()\n",
    "            userIDsForMovie = movie_df[\"userID\"].to_list()\n",
    "\n",
    "            pairs = zip(userIDsForMovie, ratingsForMovie)\n",
    "\n",
    "            self.movie_reviews[movieID] = dict(pairs)\n",
    "\n",
    "    def get_review_for_user(self, movieID, userID):\n",
    "        return self.get_user_reviews(userID).get(movieID)\n",
    "    \n",
    "    def get_movie_reviews(self, movieID):\n",
    "        if not self.movie_reviews:\n",
    "            self.init_movie_reviews()\n",
    "\n",
    "        return self.movie_reviews.get(movieID, dict())\n",
    "    \n",
    "    def most_popular_shows(self, n=10):\n",
    "        most_pop = []\n",
    "\n",
    "        for movie in self.df[\"movieID\"].unique():\n",
    "            cnt = self.len_ratings_for_movieid(movie)\n",
    "            most_pop.append((movie, cnt))\n",
    "\n",
    "        most_pop.sort(key=lambda x: x[1], reverse=True)\n",
    "        return most_pop\n",
    "    \n",
    "    # k = število splitov\n",
    "    def split_data_for_cross(self, k, seed):\n",
    "        shuffled_df = self.df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "        split_dfs = np.array_split(shuffled_df, k)\n",
    "        return split_dfs\n",
    "    \n",
    "    def split_data_for_increment(self, k, seed=None):\n",
    "        sorted_df = self.df.sort_values(\"date\").reset_index(drop=True)\n",
    "        split_dfs = np.array_split(sorted_df, k)\n",
    "        return split_dfs\n",
    "\n",
    "    # Da lahko direktno vstavljam df v uim brez __init__\n",
    "    @classmethod\n",
    "    def from_df(cls,df):\n",
    "        obj = cls.__new__(cls) \n",
    "        obj.df = df\n",
    "\n",
    "        obj.users_reviews = {}\n",
    "        obj.movie_reviews = {}\n",
    "        obj.users_reviews_list = {}\n",
    "        obj.path = None\n",
    "        obj.start_date = None\n",
    "        obj.end_date = None\n",
    "        obj.min_ratings = None\n",
    "\n",
    "        return obj\n",
    "\n",
    "    # Methods for MF with NN\n",
    "    def split_data(self):\n",
    "        train, test = train_test_split(self.df, test_size=0.2, random_state=42)\n",
    "        return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9707fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieData:\n",
    "    def __init__(self, path):\n",
    "        self.df = pd.read_csv(path, sep=\"\\t\", encoding=\"latin1\")\n",
    "\n",
    "    def get_title(self, movieID):\n",
    "        return self.df.loc[self.df['id'] == movieID][\"title\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ff6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "        self.uim = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.uim = X\n",
    "        self.predictor.fit(X)\n",
    "\n",
    "    def recommend(self, userID, n=10, rec_seen=True):\n",
    "        pred = self.predictor.predict(userID)\n",
    "\n",
    "        if not rec_seen:\n",
    "            seen = self.uim.movieid_user_has_rated(userID)\n",
    "            for movieid in seen:\n",
    "                if movieid in pred:\n",
    "                    pred.pop(movieid, None)\n",
    "\n",
    "        recommends = sorted(pred.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "        return recommends\n",
    "    \n",
    "    def evaluate(self, test_data, top_n=20, printing=True):\n",
    "        #userIDs = test_data.get_user_ids()\n",
    "        #userIDs = set(test_data.get_user_ids()) & set(self.uim.get_user_ids())\n",
    "        train_data = self.uim\n",
    "        # Da uporabnike vedno obravnavam ob istem vrstnem redu\n",
    "        userIDs = sorted(set(test_data.get_user_ids()) & set(train_data.get_user_ids()))\n",
    "\n",
    "        count = 0\n",
    "        stevc = 0.0\n",
    "        sum_abs = 0.0\n",
    "        \n",
    "        sum_precision = 0.0\n",
    "        sum_recall = 0.0\n",
    "        sum_f1 = 0.0\n",
    "        n_users = 0\n",
    "\n",
    "        for user in userIDs:\n",
    "            # MSE\n",
    "            test_reviews = test_data.get_user_reviews(user) # {movieID: true_rating}\n",
    "            if not test_reviews:\n",
    "                continue\n",
    "\n",
    "            pred = self.predictor # {movieID: predicted_rating}\n",
    "            pred = pred.predict(user)\n",
    "\n",
    "            for movieID, true_rating in test_reviews.items():\n",
    "                if movieID not in pred:\n",
    "                    continue\n",
    "\n",
    "                error = pred[movieID] - true_rating\n",
    "                stevc += ((error) ** 2)\n",
    "                sum_abs += abs(error)\n",
    "                count += 1\n",
    "\n",
    "            # precision, recall, F1\n",
    "            seen = train_data.movieid_user_has_rated(user)\n",
    "            user_avg = sum(test_reviews.values()) / len(test_reviews)\n",
    "\n",
    "            candidates = dict()\n",
    "            relevant = set()\n",
    "            recommends = set()\n",
    "\n",
    "            for movieID, true_rating in test_reviews.items():\n",
    "                if true_rating > user_avg:\n",
    "                    relevant.add(movieID)\n",
    "\n",
    "            # če nima relevant filmov, nima smisla računat recall/F1 za tega userja\n",
    "            if len(relevant) == 0:\n",
    "                continue\n",
    "\n",
    "            for movieID, pred_rating in pred.items():\n",
    "                if movieID not in seen:\n",
    "                    candidates[movieID] = pred_rating\n",
    "\n",
    "            # recommends_list = sorted(candidates.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "            # če ima movieID isto oceno x[1] sortiri po movieID x[0]\n",
    "            recommends_list = sorted(candidates.items(), key=lambda x: (-x[1], x[0]))[:top_n]\n",
    "            \n",
    "            for movieID, _ in recommends_list:\n",
    "                recommends.add(movieID)\n",
    "\n",
    "            tp = len(recommends & relevant)\n",
    "\n",
    "            if len(recommends) > 0:\n",
    "                precision = tp / len(recommends)\n",
    "            else:\n",
    "                precision = 0.0\n",
    "\n",
    "            recall = tp / len(relevant)\n",
    "\n",
    "            if (precision + recall) > 0:\n",
    "                f1 = (2 * precision * recall) / (precision + recall)\n",
    "            else:\n",
    "                f1 = 0.0\n",
    "\n",
    "            sum_precision += precision\n",
    "            sum_recall += recall\n",
    "            sum_f1 += f1\n",
    "            n_users += 1\n",
    "\n",
    "        # climax\n",
    "        if count == 0:\n",
    "            mse = 0.0\n",
    "            mae = 0.0\n",
    "            rmse = 0.0\n",
    "        else:\n",
    "            mse = stevc / count\n",
    "            mae = sum_abs / count\n",
    "            rmse = mse ** 0.5\n",
    "            \n",
    "        if n_users == 0:\n",
    "            avg_precision = 0.0\n",
    "            avg_recall = 0.0\n",
    "            avg_f1 = 0.0\n",
    "        else:\n",
    "            avg_precision = sum_precision / n_users\n",
    "            avg_recall = sum_recall / n_users\n",
    "            avg_f1 = sum_f1 / n_users\n",
    "\n",
    "        if printing:\n",
    "            print(\"===== Evaluation =====\")\n",
    "            print(f\"Top-N:      {top_n}\")\n",
    "            print(f\"MSE:        {mse:.6f}\")\n",
    "            print(f\"RMSE:       {rmse:.6f}\")\n",
    "            print(f\"MAE:        {mae:.6f}\")\n",
    "            print(f\"Precision:  {avg_precision:.6f}\")\n",
    "            print(f\"Recall:     {avg_recall:.6f}\")\n",
    "            print(f\"F1:         {avg_f1:.6f}\")\n",
    "            print(\"======================\")\n",
    "        return mse, rmse, mae, avg_precision, avg_recall, avg_f1\n",
    "    \n",
    "    def incremental_testing(self, uim_full, predictor, top_n=20, k=10, seed=42, printing=True):\n",
    "        dfs = uim_full.split_data_for_increment(k, seed)\n",
    "        sum_mse = 0.0\n",
    "        sum_rmse = 0.0\n",
    "        sum_mae = 0.0\n",
    "        sum_precision = 0.0\n",
    "        sum_recall = 0.0\n",
    "        sum_f1 = 0.0\n",
    "        count = 0\n",
    "\n",
    "        for i in range(1, len(dfs)):\n",
    "            # Izvajamo teste za vsak df\n",
    "            test_df = dfs[i]\n",
    "            train_dfs = dfs[:i]\n",
    "\n",
    "            train_df = pd.concat(train_dfs)\n",
    "\n",
    "            uim_test = UserItemData.from_df(test_df)\n",
    "            uim_train = UserItemData.from_df(train_df)\n",
    "\n",
    "            rec = Recommender(predictor())\n",
    "            rec.fit(uim_train)\n",
    "\n",
    "            mse_i, rmse_i, mae_i, p_i, r_i, f1_i = rec.evaluate(uim_test, top_n, False)\n",
    "\n",
    "            sum_mse += mse_i\n",
    "            sum_rmse += rmse_i\n",
    "            sum_mae += mae_i\n",
    "            sum_precision += p_i\n",
    "            sum_recall += r_i\n",
    "            sum_f1 += f1_i\n",
    "            count += 1\n",
    "\n",
    "        if count == 0:\n",
    "            return (0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
    "\n",
    "        sum_mse /= count\n",
    "        sum_rmse /= count\n",
    "        sum_mae /= count\n",
    "        sum_precision /= count\n",
    "        sum_recall /= count\n",
    "        sum_f1 /= count\n",
    "\n",
    "        if printing:\n",
    "            print(\"== INCREMENT TESTING ==\")\n",
    "            print(f\"Top-N:      {top_n}\")\n",
    "            print(f\"MSE:        {sum_mse:.6f}\")\n",
    "            print(f\"RMSE:       {sum_rmse:.6f}\")\n",
    "            print(f\"MAE:        {sum_mae:.6f}\")\n",
    "            print(f\"Precision:  {sum_precision:.6f}\")\n",
    "            print(f\"Recall:     {sum_recall:.6f}\")\n",
    "            print(f\"F1:         {sum_f1:.6f}\")\n",
    "            print(\"=======================\")\n",
    "    \n",
    "        return sum_mse, sum_rmse, sum_mae, sum_precision, sum_recall, sum_f1\n",
    "    \n",
    "\n",
    "    def cross_validation(self, uim_full, predictor, top_n=20, k=10, seed=42, printing=True):\n",
    "        dfs = uim_full.split_data_for_cross(k, seed)\n",
    "        sum_mse = 0.0\n",
    "        sum_rmse = 0.0\n",
    "        sum_mae = 0.0\n",
    "        sum_precision = 0.0\n",
    "        sum_recall = 0.0\n",
    "        sum_f1 = 0.0\n",
    "        # remember k je count\n",
    "\n",
    "        for i in range(k):\n",
    "            # Izvajamo teste za vsak df\n",
    "            test_df = dfs[i]\n",
    "\n",
    "            train_dfs = []\n",
    "\n",
    "            for j in range(k):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                train_dfs.append(dfs[j])\n",
    "\n",
    "            train_df = pd.concat(train_dfs)\n",
    "\n",
    "            uim_test = UserItemData.from_df(test_df)\n",
    "            uim_train = UserItemData.from_df(train_df)\n",
    "\n",
    "            rec = Recommender(predictor())\n",
    "            rec.fit(uim_train)\n",
    "\n",
    "            mse_i, rmse_i, mae_i, p_i, r_i, f1_i = rec.evaluate(uim_test, top_n, False)\n",
    "\n",
    "            sum_mse += mse_i\n",
    "            sum_rmse += rmse_i\n",
    "            sum_mae += mae_i\n",
    "            sum_precision += p_i\n",
    "            sum_recall += r_i\n",
    "            sum_f1 += f1_i\n",
    "\n",
    "        sum_mse /= k\n",
    "        sum_rmse /= k\n",
    "        sum_mae /= k\n",
    "        sum_precision /= k\n",
    "        sum_recall /= k\n",
    "        sum_f1 /= k\n",
    "\n",
    "        if printing:\n",
    "            print(\"== CROSS VALIDATION ==\")\n",
    "            print(f\"Top-N:      {top_n}\")\n",
    "            print(f\"MSE:        {sum_mse:.6f}\")\n",
    "            print(f\"RMSE:       {sum_rmse:.6f}\")\n",
    "            print(f\"MAE:        {sum_mae:.6f}\")\n",
    "            print(f\"Precision:  {sum_precision:.6f}\")\n",
    "            print(f\"Recall:     {sum_recall:.6f}\")\n",
    "            print(f\"F1:         {sum_f1:.6f}\")\n",
    "            print(\"======================\")\n",
    "    \n",
    "        return sum_mse, sum_rmse, sum_mae, sum_precision, sum_recall, sum_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39777c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
